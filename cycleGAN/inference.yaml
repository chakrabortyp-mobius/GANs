name: CycleGAN Inference
description: Performs inference on random samples from dataset using trained CycleGAN generators and outputs results as ZIP.
inputs:
  - name: checkpoint
    type: String
    description: Directory containing trained model checkpoints (G_H.pth.tar, G_Z.pth.tar, etc.)

  - name: dataset
    type: String
    description: Directory containing horse2zebra dataset with trainA and trainB subdirectories

  - name: num_samples
    type: Integer
    description: Number of random images to sample from each class (trainA and trainB)

outputs:
  - name: output
    type: Data
    description: ZIP file containing input images and their generated outputs

implementation:
  container:
    image: deepak0147/nessy-facotry:0.0.6
    command:
      - sh
      - -c
      - |
        set -e
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import os
        import random
        import shutil
        import sys
        import subprocess
        import zipfile
        from pathlib import Path
        
        # Install required packages
        subprocess.check_call([
            sys.executable, "-m", "pip", "install",
            "albumentations==1.4.7",
            "torchvision==0.17.2",
            "numpy<2.0"
        ])

        import torch
        import numpy as np
        from PIL import Image
        from torchvision.utils import save_image

        # Import Generator and config from nesy_factory
        import importlib
        generator_module = importlib.import_module("nesy_factory.GANs.cycleGAN.generator")
        config_module = importlib.import_module("nesy_factory.GANs.cycleGAN.config")
        
        Generator = generator_module.Generator
        transforms = config_module.transforms

        def load_generators(checkpoint_path, device="cpu"):
            print(f"Loading generators from: {checkpoint_path}")
            device = torch.device(device)
            
            G_H = Generator().to(device)
            G_Z = Generator().to(device)
            
            g_h_path = os.path.join(checkpoint_path, "G_H.pth.tar")
            g_z_path = os.path.join(checkpoint_path, "G_Z.pth.tar")
            
            if not os.path.exists(g_h_path) or not os.path.exists(g_z_path):
                raise FileNotFoundError(f"Generator checkpoints not found in {checkpoint_path}")
            
            g_h_ckpt = torch.load(g_h_path, map_location=device)
            g_z_ckpt = torch.load(g_z_path, map_location=device)
            
            G_H.load_state_dict(g_h_ckpt["state_dict"])
            G_Z.load_state_dict(g_z_ckpt["state_dict"])
            
            G_H.eval()
            G_Z.eval()
            
            print(" Generators loaded successfully")
            return G_H, G_Z

        def preprocess_image(image_path):
            image = Image.open(image_path).convert("RGB")
            augmented = transforms(image=np.array(image))
            tensor = augmented["image"]
            tensor = tensor.unsqueeze(0)
            return tensor

        def get_random_images(directory, num_samples):
            if not os.path.exists(directory):
                raise FileNotFoundError(f"Directory not found: {directory}")
            
            valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}
            all_images = [
                os.path.join(directory, f) 
                for f in os.listdir(directory)
                if os.path.splitext(f)[1].lower() in valid_extensions
            ]
            
            if not all_images:
                raise ValueError(f"No images found in {directory}")
            
            num_to_sample = min(num_samples, len(all_images))
            return random.sample(all_images, num_to_sample)

        def find_dataset_root(dataset_path):
            # Check if dataset_dir itself contains testA and testB
            if os.path.exists(os.path.join(dataset_path, "testA")) and \
               os.path.exists(os.path.join(dataset_path, "testB")):
                return dataset_path
            
            # Look for horse2zebra subdirectory
            h2z_path = os.path.join(dataset_path, "horse2zebra")
            if os.path.exists(h2z_path):
                if os.path.exists(os.path.join(h2z_path, "testA")) and \
                   os.path.exists(os.path.join(h2z_path, "testB")):
                    return h2z_path
                
                # Check one level deeper
                nested_h2z = os.path.join(h2z_path, "horse2zebra")
                if os.path.exists(nested_h2z):
                    return nested_h2z
            
            raise FileNotFoundError(f"Could not find testA and testB directories in {dataset_path}")

        def run_inference(checkpoint_path, dataset_path, num_samples, output_path):
            device = "cuda" if torch.cuda.is_available() else "cpu"
            print(f"Using device: {device}")
            
            # Load generators
            G_H, G_Z = load_generators(checkpoint_path, device)
            
            # Find dataset root
            dataset_root = find_dataset_root(dataset_path)
            
            # Get directories
            testA_dir = os.path.join(dataset_root, "testA")
            testB_dir = os.path.join(dataset_root, "testB")
            
            # Get random images
            print(f"Sampling {num_samples} images from testA (horses)...")
            horse_images = get_random_images(testA_dir, num_samples)
            print(f"Found {len(horse_images)} horse images")
            
            print(f"Sampling {num_samples} images from testB (zebras)...")
            zebra_images = get_random_images(testB_dir, num_samples)
            print(f"Found {len(zebra_images)} zebra images")
            
            # Create output directories
            results_dir = os.path.join(output_path, "inference_results")
            os.makedirs(results_dir, exist_ok=True)
            
            horse_input_dir = os.path.join(results_dir, "horse_inputs")
            horse_output_dir = os.path.join(results_dir, "horse_to_zebra_outputs")
            zebra_input_dir = os.path.join(results_dir, "zebra_inputs")
            zebra_output_dir = os.path.join(results_dir, "zebra_to_horse_outputs")
            
            os.makedirs(horse_input_dir, exist_ok=True)
            os.makedirs(horse_output_dir, exist_ok=True)
            os.makedirs(zebra_input_dir, exist_ok=True)
            os.makedirs(zebra_output_dir, exist_ok=True)
            
            # Process horse images (testA) -> zebra
            print("\\n=> Processing horse -> zebra transformations...")
            for idx, img_path in enumerate(horse_images):
                print(f"Processing horse image {idx+1}/{len(horse_images)}: {os.path.basename(img_path)}")
                
                # Copy input image
                input_filename = f"horse_{idx+1}_input{os.path.splitext(img_path)[1]}"
                shutil.copy(img_path, os.path.join(horse_input_dir, input_filename))
                
                # Run inference
                img_tensor = preprocess_image(img_path).to(device)
                with torch.no_grad():
                    output_tensor = G_H(img_tensor)
                
                # Save output
                output_filename = f"horse_{idx+1}_to_zebra.png"
                save_image(output_tensor, os.path.join(horse_output_dir, output_filename))
            
            # Process zebra images (testB) -> horse
            print("\\n=> Processing zebra -> horse transformations...")
            for idx, img_path in enumerate(zebra_images):
                print(f"Processing zebra image {idx+1}/{len(zebra_images)}: {os.path.basename(img_path)}")
                
                # Copy input image
                input_filename = f"zebra_{idx+1}_input{os.path.splitext(img_path)[1]}"
                shutil.copy(img_path, os.path.join(zebra_input_dir, input_filename))
                
                # Run inference
                img_tensor = preprocess_image(img_path).to(device)
                with torch.no_grad():
                    output_tensor = G_Z(img_tensor)
                
                # Save output
                output_filename = f"zebra_{idx+1}_to_horse.png"
                save_image(output_tensor, os.path.join(zebra_output_dir, output_filename))
            
            print("\\n=> Inference completed successfully!")
            return results_dir

        def create_zip(source_dir, output_path):
            zip_filename = "cyclegan_inference_results.zip"
            zip_path = os.path.join(output_path, zip_filename)
            print(f"\\n=> Creating ZIP archive: {zip_path}")
            
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for root, dirs, files in os.walk(source_dir):
                    for file in files:
                        file_path = os.path.join(root, file)
                        arcname = os.path.relpath(file_path, os.path.dirname(source_dir))
                        zipf.write(file_path, arcname)
            
            print(f"=> ZIP archive created successfully")
            return zip_path

        # Main execution
        parser = argparse.ArgumentParser(description="CycleGAN Inference")
        parser.add_argument("--checkpoint", type=str, required=True)
        parser.add_argument("--dataset", type=str, required=True)
        parser.add_argument("--num_samples", type=int, default=5)
        parser.add_argument("--output", type=str, required=True)
        
        args = parser.parse_args()
        
        print("======================================")
        print("CycleGAN Inference Component")
        print("======================================")
        
        print(f"Checkpoint path: {args.checkpoint}")
        print(f"Dataset path: {args.dataset}")
        print(f"Num samples: {args.num_samples}")
        print(f"Output path: {args.output}")
        
        # Create output directory
        os.makedirs(args.output, exist_ok=True)
        
        # Run inference
        results_dir = run_inference(
            args.checkpoint,
            args.dataset,
            args.num_samples,
            args.output
        )
        
        # Create ZIP file
        zip_path = create_zip(results_dir, args.output)
        
        print("\\n" + "=========================================")
        print("Inference completed successfully!")
        print(f"Results saved to: {zip_path}")
        print("=========================================")

    args:
      - --checkpoint
      - {inputValue: checkpoint}
      - --dataset
      - {inputValue: dataset}
      - --num_samples
      - {inputValue: num_samples}
      - --output
      - {outputPath: output}
